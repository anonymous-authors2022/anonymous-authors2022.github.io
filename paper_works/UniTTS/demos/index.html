<html>
  <head>
    <meta charset="UTF-8">
    <title>UniTTS Demo Samples</title>
  </head>
  <body>
    <article>
      <header>
        <h1>UniTTS Demo Samples</h1>
      </header>
    </article>

    <div>
        <h3>Authors</h3>
        Anonymous Authors
    </div>
    <div>
        <h3>Abstract</h3>
            We propose a novel high-fidelity expressive speech synthesis model, UniTTS, that learns and controls multiple non-hierarchically correlated attributes without conflict. 
            UniTTS represents phonemes and non-linguistic attributes in a single unified embedding space. 
            The proposed method is particularly effective in reflecting both speaker ID and emotion because it does not add the variance by the two overlapping attributes redundantly, and predicts prosodic attributes based on the speaker and emotion IDs. 
            UniTTS learns the unified embedding space leveraging a residual network that extends FastSpeech2. 
            We additionally applied a data augmentation technique to improve the fidelity and controllability over the non-linguistic attributes. 
            In experiments, the visualization results exhibited that UniTTS successfully learned multiple attributes in the unified embedding space. 
            As well, UniTTS synthesized high-fidelity speech signals while controlling multiple attributes, and transferred speech style from the reference speech.
    </div>
    
    <br>

    <div>
        <h2>Visualization of Unified Embedding Space</h2>
        These visualization results illustrate the latent space of style attributes modeled by UniTTS. <br>
        We used EmotionTTS dataset for visualization. EmotionTTS dataset consists of 15 speakers and 4 emotions(neutral, happy, sad and angry).

        <h3>Initial phoneme embeddings that does not contain style information</h3>
        
        <table style="text-align:center">
            <tr>
                <th><img src="./samples/visualizations/4-a.gif" width=400> </th>
                <th><img src="./samples/visualizations/4-b.gif" width=400> </th>
                <th><img src="./samples/visualizations/4-c.gif" width=400> </th>
            </tr>
            <tr>
                <th>(a) Initial phoneme embeddings<br> colored by phoneme type</th>
                <th>(b) Initial phoneme embeddings<br> colored by speaker label</th>
                <th>(c) Initial phoneme embeddings<br> colored by emotion label</th>
            </tr>
        </table>
        <br>
        These figures are the t-SNE visualization of the distribution of the unstyled phoneme embeddings extracted from the locations marked as A in Figure 3 (please refer the paper).<br> 
        (a) shows that the unstyled phoneme embedding represents phoneme types, while (b)and (c) show that it does not contain speaker or emotion information. <br>

        <br>

        <h3>Residual embeddings of style attributes (speaker ID, emotion, pitch and energy)</h3>
        <table style="text-align:center">
            <tr>
                <th><img src="./samples/visualizations/5-a.gif" width=400> </th>
                <th><img src="./samples/visualizations/5-b.gif" width=400> </th>
                <th><img src="./samples/visualizations/5-c.png" width=400> </th>
                <th><img src="./samples/visualizations/5-d.png" width=400> </th>
                
            </tr>
            <tr>
                <th>(a) t-SNE visualization of speaker embeddings<br> (B-A) colored by speaker label</th>
                <th>(b) t-SNE visualization of emotion embeddings<br> (C-B) colored by emotion label</th>
                <th>(c) PCA visualization of pitch embeddings<br> (E-D) colored by predicted pitch value</th>
                <th>(d) PCA visualization of energy embeddings<br> (F-E) colored by predicted energy value</th>
            </tr>
        </table>
        <br>
        These figures are the distribution of the residual embeddings of speaker, emotion, pitch, and energy. (Please note that A, B, C, D, E and F are denoted in paper-figure 3.) <br>
        The uppercase letters indicate the locations in Fig. 3 where the embeddings were extracted. <br>
        These figures show that the residual embeddings are effective in representing the style attributes.
        
        <br><br>

        <h3>Full style embeddings that jointly represent all attributes (speaker ID, emotion, unlabeled local prosody, pitch, and energy)</h3>
        <table style="text-align:center">
            <tr>
                <th><img src="./samples/visualizations/6-a.gif" width=400> </th>
                <th><img src="./samples/visualizations/6-b.gif" width=400> </th>
                <th><img src="./samples/visualizations/6-c.gif" width=400> </th>
                <th><img src="./samples/visualizations/6-d.gif" width=400> </th>
                
            </tr>
            <tr>
                <th>(a) Full style embeddings(F-A)<br> colored by speaker label</th>
                <th>(b) Full style embeddings(F-A)<br> colored by emotion label</th>
                <th>(c) Full style embeddings<br> normalized by speaker embedding<br> (F-B) colored by speaker label</th>
                <th>(d) Full style embeddings<br> normalized by speaker embedding<br> (F-B) colored by emotion label</th>
            </tr>
        </table>
        <br>
        These figures are the t-SNE visualization of the distribution of the full style embeddings that incorporate all style attributes. <br>
        The uppercase letters indicate the locations in Fig. 3 where the embeddings were extracted. <br>
        (a) and (b)show that the full style embedding contains both speaker and emotion information. <br>
        (c) shows that the full style embedding normalized by the means of the speaker embeddings does not contain speaker information. <br>
        (d) shows that the variance in emotion is dominant after normalizing the full style embedding by the means of speaker embeddings. <br>
    </div>

    <br><br>

    <div>
        <h2> Speaker and emotion modeling </h2>

        These audio samples demonstrate the speaker and emotion modeling performance of UniTTS. <br>

        <table style="text-align:center">
            <tr>
                <th> </th>
                <th>neutral</th>
                <th>happy</th>
                <th>sad</th>
                <th>angry</th>
    
            </tr>
            <tr>
                <td>nea speaker mel</td>
                <td><img src="samples/speaker_and_emotion_modeling/2_nea_neu.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/2_nea_hap.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/2_nea_sad.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/2_nea_ang.png" height=150></td>
            </tr>
            <tr>
		        <td>nea speaker wav</td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/2_nea_neu.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/2_nea_hap.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/2_nea_sad.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/2_nea_ang.wav"></audio></td>
            </tr>
            <tr>
                <td>nem speaker mel</td>
                <td><img src="samples/speaker_and_emotion_modeling/1_nem_neu.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/1_nem_hap.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/1_nem_sad.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/1_nem_ang.png" height=150></td>
            </tr>
            <tr>
		        <td>nem speaker wav</td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/1_nem_neu.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/1_nem_hap.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/1_nem_sad.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/1_nem_ang.wav"></audio></td>
            </tr>
            <tr>
                <td>nec speaker mel</td>
                <td><img src="samples/speaker_and_emotion_modeling/3_nec_neu.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/3_nec_hap.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/3_nec_sad.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/3_nec_ang.png" height=150></td>
            </tr>
            <tr>
		        <td>nec speaker wav</td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/3_nec_neu.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/3_nec_hap.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/3_nec_sad.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/3_nec_ang.wav"></audio></td>
            </tr>
            <tr>
                <td>neo speaker mel</td>
                <td><img src="samples/speaker_and_emotion_modeling/4_neo_neu.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/4_neo_hap.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/4_neo_sad.png" height=150></td>
                <td><img src="samples/speaker_and_emotion_modeling/4_neo_ang.png" height=150></td>
            </tr>
            <tr>
		        <td>neo speaker wav</td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/4_neo_neu.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/4_neo_hap.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/4_neo_sad.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_and_emotion_modeling/4_neo_ang.wav"></audio></td>
            </tr>
        </table>
    </div>

    <div>
        <h2>Energy and Pitch Control (with and without Transform-aware Data Augmentation)</h2>

        <h3>Energy control</h3>

        The following samples were synthesized by UniTTS with increased, the original, and decreased energy values	<br>

        &nbsp;&nbsp;&nbsp;&nbsp; - Row 1: the ground truth samples and augmented samples whose energy values were increased or decreased using the SOX toolkit.<br>
        &nbsp;&nbsp;&nbsp;&nbsp; - Row 2: the audio samples synthesized by UniTTS applying data augmentation <br>
        &nbsp;&nbsp;&nbsp;&nbsp; - Row 3: the audio samples synthesized by UniTTS not applying data augmentation<br><br>
    
        Without data augmentation, UniTTS produced speech samples with deteriorated quality when the energy value was increased or decreased. Particularly, when the energy value was decreased, it produced severly broken and distorted samples. <br>
        However, when applying data augmentation, it produced clean samples even with increased or decreased energy values. <br><br>
    
        <table style="text-align:center">
            <tr>
                <th></th>
                <th>increased energy values</th>
                <th>the original energy values</th>
                <th>decreased energy values</th>
    
            </tr>

            <tr>
                <td>GT mel</td>
                <td><img src="samples/data_aug/energy/GT_plus.png"></td>
                <td><img src="samples/data_aug/energy/GT.png"></td>
                <td><img src="samples/data_aug/energy/GT_minus.png"></td>
            </tr>

            <tr>
                <td>GT wavs</td>
                <td><audio controls><source src="samples/data_aug/energy/GT_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/energy/GT.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/energy/GT_minus.wav"></audio></td>
            </tr>

            <tr>
                <td>w/ data aug. mel</td>
                <td><img src="samples/data_aug/energy/data_aug_plus.png"></td>
                <td><img src="samples/data_aug/energy/data_aug.png"></td>
                <td><img src="samples/data_aug/energy/data_aug_minus.png"></td>
            </tr>

            <tr>
                <td>w/ data aug. wavs</td>
                <td><audio controls><source src="samples/data_aug/energy/data_aug_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/energy/data_aug.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/energy/data_aug_minus.wav"></audio></td>
            </tr>

            <tr>
                <td>w/o data aug. mel</td>
                <td><img src="samples/data_aug/energy/wo_data_aug_plus.png"></td>
                <td><img src="samples/data_aug/energy/wo_data_aug.png"></td>
                <td><img src="samples/data_aug/energy/wo_data_aug_minus.png"></td>
            </tr>

            <tr>
                <td>w/o data aug. wavs</td>
                <td><audio controls><source src="samples/data_aug/energy/wo_data_aug_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/energy/wo_data_aug.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/energy/wo_data_aug_minus.wav"></audio></td>
            </tr>
        </table>

        <br>

        <h3>Pitch control</h3>

        The following samples were synthesized by UniTTS with increased, the original, and decreased pitch values <br>
        Please note that adjusting the pitch of the voice using the SOX toolkit has a side-effect that changes the timbre as shown in the first row. <br>
    
        &nbsp;&nbsp;&nbsp;&nbsp; - Row 1: the ground truth samples and augmented samples whose pitch values were increased or decreased using the SOX toolkit. <br>
        &nbsp;&nbsp;&nbsp;&nbsp; - Row 2: the audio samples synthesized by UniTTS applying data augmentation <br>
        &nbsp;&nbsp;&nbsp;&nbsp; - Row 3: the audio samples synthesized by UniTTS not applying data augmentation <br><br>
    
        Without data augmentation, UniTTS shows limited ability to control pitch, as shown more clearly in the spectrograms. <br>
        When applying data augmentation, it controlled pitch more effectively but changed timbre, because it was trained with the augmented samples whose timbre was changed due to the side-effect of the SOX toolkit. <br>
        We ask the listener to compare the samples focusing on the ability to control pitch.<br><br>

        <table style="text-align:center">
            <tr>
                <th></th>
                <th>increased pitch values</th>
                <th>the original pitch values</th>
                <th>decreased pitch values</th>
    
            </tr>
            <tr>
                <td>GT mel</td>
                <td><img src="samples/data_aug/pitch/GT_plus.png"></td>
                <td><img src="samples/data_aug/pitch/GT.png"></td>
                <td><img src="samples/data_aug/pitch/GT_minus.png"></td>
            </tr>

            <tr>
                <td>GT wavs</td>
                <td><audio controls><source src="samples/data_aug/pitch/GT_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch/GT.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch/GT_minus.wav"></audio></td>
            </tr>

            <tr>
                <td>w/ data aug. mel</td>
                <td><img src="samples/data_aug/pitch/data_aug_plus.png"></td>
                <td><img src="samples/data_aug/pitch/data_aug.png"></td>
                <td><img src="samples/data_aug/pitch/data_aug_minus.png"></td>
            </tr>

            <tr>
                <td>w/ data aug. wavs</td>
                <td><audio controls><source src="samples/data_aug/pitch/data_aug_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch/data_aug.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch/data_aug_minus.wav"></audio></td>
            </tr>

            <tr>
                <td>w/o data aug. mel</td>
                <td><img src="samples/data_aug/pitch/wo_data_aug_plus.png"></td>
                <td><img src="samples/data_aug/pitch/wo_data_aug.png"></td>
                <td><img src="samples/data_aug/pitch/wo_data_aug_minus.png"></td>
            </tr>

            <tr>
                <td>w/o data aug. wavs</td>
                <td><audio controls><source src="samples/data_aug/pitch/wo_data_aug_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch/wo_data_aug.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch/wo_data_aug_minus.wav"></audio></td>
            </tr>
        </table>


        <br>

        <h3>Pitch and energy control</h3>

        The following samples were synthesized by UniTTS controling both pitch and energy. <br>
        Applying data augmenation, UniTTS can effectively control pitch and energy. <br><br>
    
        <table style="text-align:center">
            <tr>
                <th></th>
                <th>the original pitch and energy values</th>
                <th>pitch +, energy +</th>
                <th>pitch +, energy -</th> 
                <th>pitch -, energy +</th> 
                <th>pitch -, energy -</th> 
                
            </tr>

            <tr>
                <td>GT mel</td>
                <td><img src="samples/data_aug/pitch_and_energy/GT.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/GT_plus_plus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/GT_plus_minus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/GT_minus_plus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/GT_minus_minus.png"></td>
            </tr>

            <tr>
                <td>GT wavs</td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/GT.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/GT_plus_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/GT_plus_minus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/GT_minus_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/GT_minus_minus.wav"></audio></td>
            </tr>

            <tr>
                <td>w/ data aug. mel</td>
                <td><img src="samples/data_aug/pitch_and_energy/data_aug.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/data_aug_plus_plus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/data_aug_plus_minus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/data_aug_minus_plus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/data_aug_minus_minus.png"></td>
            </tr>

            <tr>
                <td>w/ data aug. wavs</td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/data_aug.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/data_aug_plus_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/data_aug_plus_minus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/data_aug_minus_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/data_aug_minus_minus.wav"></audio></td>
            </tr>

            <tr>
                <td>w/o data aug. mel</td>
                <td><img src="samples/data_aug/pitch_and_energy/wo_data_aug.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/wo_data_aug_plus_plus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/wo_data_aug_plus_minus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/wo_data_aug_minus_plus.png"></td>
                <td><img src="samples/data_aug/pitch_and_energy/wo_data_aug_minus_minus.png"></td>
            </tr>

            <tr>
                <td>w/o data aug. wavs</td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/wo_data_aug.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/wo_data_aug_plus_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/wo_data_aug_plus_minus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/wo_data_aug_minus_plus.wav"></audio></td>
                <td><audio controls><source src="samples/data_aug/pitch_and_energy/wo_data_aug_minus_minus.wav"></audio></td>
            </tr>
        </table>
    </div>

    <br><br><br>

    <div>
        <h2>Style Mixing</h2>
        <h3>Speaker identity transfer</h3>
        The first two columns show the synthesized samples with different speaker and emotion IDs. <br>
        We extracted the speaker embedding used to synthesize the first samples and other propody embeddings used to synthesize the second samples. <br>
        Then, we combined the embeddings to synthesize the third samples. <br>
        The third samples have the timbre of the first samples and the style of the second samples.<br>
        <br><br>
        <table style="text-align:center">
            <tr>
                <th></th>
                <th>The sources of speaker embedding</th>
                <th></th>
                <th>The sources of other style embeddings</th>
                <th></th>
                <th>The samples synthesized <br> with the combined style embedding</th>
            </tr>

            <tr>
                <td>emh speaker + emg(angry)'s prosody mel</td>
                <td><img src="samples/style_mixing/speaker/male_male_speaker.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/speaker/male_male_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/speaker/male_male_mixed.png"></td>
            </tr>
            <tr>
                <td>emh speaker + emg(angry)'s prosody wav</td>
                <td><audio controls><source src="samples/style_mixing/speaker/male_male_speaker.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/male_male_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/male_male_mixed.wav"></audio></td>
            </tr>
            <tr>
                <td>emh speaker + emb(happy)'s prosody mel</td>
                <td><img src="samples/style_mixing/speaker/male_female_speaker.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/speaker/male_female_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/speaker/male_female_mixed.png"></td>
            </tr>
            <tr>
                <td>emh speaker + emb(happy)'s prosody wav</td>
                <td><audio controls><source src="samples/style_mixing/speaker/male_female_speaker.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/male_female_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/male_female_mixed.wav"></audio></td>
            </tr>

            <tr>
                <td>emb speaker + emg(angry)'s prosody mel</td>
                <td><img src="samples/style_mixing/speaker/female_male_speaker.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/speaker/female_male_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/speaker/female_male_mixed.png"></td>
            </tr>
            <tr>
                <td>emb speaker + emg(angry)'s prosody wav</td>
                <td><audio controls><source src="samples/style_mixing/speaker/female_male_speaker.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/female_male_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/female_male_mixed.wav"></audio></td>
            </tr>

            <tr>
                <td>emb speaker + ema(sad)'s prosody mel</td>
                <td><img src="samples/style_mixing/speaker/female_female_speaker.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/speaker/female_female_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/speaker/female_female_mixed.png"></td>
            </tr>
            <tr>
                <td>emb speaker + ema(sad)'s prosody wav</td>
                <td><audio controls><source src="samples/style_mixing/speaker/female_female_speaker.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/female_female_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/speaker/female_female_mixed.wav"></audio></td>
            </tr>
        </table>

        <br><br>

        <h3>Emotion representation transfer</h3>

        The first two columns show the synthesized samples with different speaker and emotion IDs. <br>
        We extracted the emotion embedding used to synthesize the first samples and other propody embeddings used to synthesize the second samples. <br>
        Then, we combined the embeddings to synthesize the third samples. <br>
        The third samples have the emotion of the first samples and the style of the second samples. <br><br>


        <table style="text-align:center">
            <tr>
                <th></th>
                <th>The sources of emotion embedding</th>
                <th></th>
                <th>The sources of other style embeddings</th>
                <th></th>
                <th>The samples synthesized <br> with the combined style embedding</th>
            </tr>

            <tr>
                <td>emb's neutral emotion + emb(sad)'s other prosodies mel</td>
                <td><img src="samples/style_mixing/emotion/neu_emotion.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/emotion/neu_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/emotion/neu_mixed.png"></td>
            </tr>
            <tr>
                <td>emb's neutral emotion + emb(sad)'s other prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/emotion/neu_emotion.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/neu_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/neu_mixed.wav"></audio></td>
            </tr>

            <tr>
                <td>emh's happy emotion + emh(angry)'s other prosodies mel</td>
                <td><img src="samples/style_mixing/emotion/hap_emotion.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/emotion/hap_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/emotion/hap_mixed.png"></td>
            </tr>
            <tr>
                <td>emh's happy emotion + emh(angry)'s other prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/emotion/hap_emotion.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/hap_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/hap_mixed.wav"></audio></td>
            </tr>

            <tr>
                <td>emg's sad emotion + emg(happy)'s other prosodies mel</td>
                <td><img src="samples/style_mixing/emotion/sad_emotion.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/emotion/sad_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/emotion/sad_mixed.png"></td>
            </tr>
            <tr>
                <td>emg's sad emotion + emg(happy)'s other prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/emotion/sad_emotion.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/sad_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/sad_mixed.wav"></audio></td>
            </tr>

            <tr>
                <td>emb's angry emotion + emb(happy)'s other prosodies mel</td>
                <td><img src="samples/style_mixing/emotion/ang_emotion.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/emotion/ang_other_prosodies.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/emotion/ang_mixed.png"></td>
            </tr>
            <tr>
                <td>emb's angry emotion + emb(happy)'s other prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/emotion/ang_emotion.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/ang_other_prosodies.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/emotion/ang_mixed.wav"></audio></td>
            </tr>
        </table>

        <br><br>

        <h3>Transfer of emotion, duration, pitch and energy from ETOD samples to KSS speaker</h3>

        The KSS dataset contains 12,853 speech samples WITHOUT emotion label spoken by a SINGLE female speaker. (Please note that no emotion label exists in KSS dataset) <br>
        The ETOD dataset contains 6,000 samples with 4 emotion types spoken by 15 speakers. <br><br>

        We transferred the style of the samples in the ETOD dataset to the KSS speaker. <br>
        We extracted the speaker embedding from the KSS samples, that do not have emotion labels, and the other style embeddings from the samples of the ETOD dataset. <br>
        Then, we synthesized speech using the combined style embedding. <br><br>
        
        The first and second columns show the samples of the KSS dataset and the ETOD dataset, respectively. <br>
        The third column shows the syntesized samples using the combined style embeddings.<br><br>

        <table style="text-align:center">
            <tr>
                <th></th>
                <th>The sources of speaker embedding.<br> (KSS dataset)</th>
                <th></th>
                <th>The sources of other style embeddings <br>(ETOD dataset)</th>
                <th></th>
                <th>The samples synthesized <br> with the combined style embedding</th>
            </tr>

            <tr>
                <td>KSS + emh speaker(angry)'s prosodies mel</td>
                <td><img src="samples/style_mixing/kss/kss_1.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/kss/male_1.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/kss/mixed_1.png"></td>
            </tr>
            <tr>
                <td>KSS + emh speaker(angry)'s prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/kss/kss_1.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/male_1.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/mixed_1.wav"></audio></td>
            </tr>

            <tr>
                <td>KSS + emg speaker(angry)'s prosodies mel</td>
                <td><img src="samples/style_mixing/kss/kss_2.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/kss/male_2.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/kss/mixed_2.png"></td>
            </tr>
            <tr>
                <td>KSS + emg speaker(angry)'s prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/kss/kss_2.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/male_2.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/mixed_2.wav"></audio></td>
            </tr>

            <tr>
                <td>KSS + emb speaker(neutral)'s prosodies mel</td>
                <td><img src="samples/style_mixing/kss/kss_3.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/kss/female_3.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/kss/mixed_3.png"></td>
            </tr>
            <tr>
                <td>KSS + emb speaker(neutral)'s prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/kss/kss_3.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/female_3.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/mixed_3.wav"></audio></td>
            </tr>

            <tr>
                <td>KSS + ema speaker(sad)'s prosodies mel</td>
                <td><img src="samples/style_mixing/kss/kss_4.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/kss/female_4.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/kss/mixed_4.png"></td>
            </tr>
            <tr>
                <td>KSS + ema speaker(sad)'s prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/kss/kss_4.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/female_4.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kss/mixed_4.wav"></audio></td>
            </tr>

        </table>

        <br><br>

        <h3>Transfer of duration, pitch, and energy from ETOD samples to KES speaker</h3>

        We transferred the duration, pitch, energy of the samples in the ETOD dataset to the KES speaker.<br>
        We extracted the speaker and emotion embeddings from the KES samples spoken by a single speaker and the duration, pitch, and energy embeddings from the samples in the ETOD dataset. <br>
        Then, we synthesized speech using the combined style embedding.<br><br>

        The first and second columns show the samples of the KES dataset and the ETOD dataset, respectively. <br>
        The third column shows the syntesized samples using the combined style embeddings.<br><br>

        <table style="text-align:center">
            <tr>
                <th></th>
                <th>The sources of speaker and emotion embeddings.<br>(KES dataset)</th>
                <th></th>
                <th>The sources of other style embeddings <br> (ETOD dataset)</th>
                <th></th>
                <th>The samples synthesized <br> with the combined style embedding.</th>
            </tr>
            <tr>
                <td>KES(disgusting) + emh speaker(angry)'s prosodies mel</td>
                <td><img src="samples/style_mixing/kes/kes_1.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/kes/other_prosodies_1.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/kes/mixed_1.png"></td>
            </tr>
            <tr>
                <td>KES(disgusting) + emh speaker(angry)'s prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/kes/kes_1.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kes/other_prosodies_1.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kes/mixed_1.wav"></audio></td>
            </tr>
            <tr>
                <td>KES(surprise) + emb speaker(sad)'s prosodies mel</td>
                <td><img src="samples/style_mixing/kes/kes_2.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/kes/other_prosodies_2.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/kes/mixed_2.png"></td>
            </tr>
            <tr>
                <td>KES(surprise) + emb speaker(sad)'s prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/kes/kes_2.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kes/other_prosodies_2.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kes/mixed_2.wav"></audio></td>
            </tr>
            <tr>
                <td>KES(fear) + emf speaker(happy)'s prosodies mel</td>
                <td><img src="samples/style_mixing/kes/kes_3.png"></td>
                <td><img width=50 src="assets/plus.png"></td>
                <td><img src="samples/style_mixing/kes/other_prosodies_3.png"></td>
                <td><img width=50 src="assets/equal.png"></td>
                <td><img src="samples/style_mixing/kes/mixed_3.png"></td>
            </tr>
            <tr>
                <td>KES(fear) + emf speaker(happy)'s prosodies wav</td>
                <td><audio controls><source src="samples/style_mixing/kes/kes_3.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kes/other_prosodies_3.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/style_mixing/kes/mixed_3.wav"></audio></td>
            </tr>
        </table>

        <br><br><br>

        <h3>Comparison to other methods</h3>

        We compared samples from UniTTS(w.o. aug) with other method such as separate embedding and gradient reversal. <br>
        UniTTS produces the most natural and similar samples compared to separate embedding and gradient reversal. <br>
        (Please note that these samples are from MOS test.)    <br>
        <br>
        Overall, UniTTS (w.o. aug) produces natural samples while keeping speaker id and emotion similarity.<br> 
        UniTTS(w.o. aug) produces best result with respect to natural duration, pitch, energy and intonation, compared to other methods.<br>
        In addition, UniTTS (w.o. aug) can preserve speaker id, even on unknown combination of speaker and emotion. 
        (e.g. speaker ema's identity and kss's curious emotion)
        <br><br>

        <table style="text-align:center">
            <tr>
                <th></th>
                <th>Reference sample</th>
                <th></th>
                <th>Separate embedding</th>
                <th>Gradient reversal</th>
                <th>UniTTS (w/o aug)</th>
            </tr>

            <tr>
                <td>sample 1</td>
                <td><audio controls><source src="samples/comparison_other_methods/GT_mel/1.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/comparison_other_methods/separate_embedding/1.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/gradient_reversal/1.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/UniTTS_wo_aug/1.wav"></audio></td>
            </tr>
            <tr>
                <td>sample 2</td>
                <td><audio controls><source src="samples/comparison_other_methods/GT_mel/2.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/comparison_other_methods/separate_embedding/2.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/gradient_reversal/2.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/UniTTS_wo_aug/2.wav"></audio></td>
            </tr>

            <tr>
                <td>sample 3</td>
                <td><audio controls><source src="samples/comparison_other_methods/GT_mel/3.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/comparison_other_methods/separate_embedding/3.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/gradient_reversal/3.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/UniTTS_wo_aug/3.wav"></audio></td>
            </tr>

            <tr>
                <td>sample 4</td>
                <td><audio controls><source src="samples/comparison_other_methods/GT_mel/4.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/comparison_other_methods/separate_embedding/4.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/gradient_reversal/4.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/UniTTS_wo_aug/4.wav"></audio></td>
            </tr>
            <tr>
                <td>unseen*</td>
                <td><audio controls><source src="samples/comparison_other_methods/GT_mel/unseen.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/comparison_other_methods/separate_embedding/unseen.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/gradient_reversal/unseen.wav"></audio></td>
                <td><audio controls><source src="samples/comparison_other_methods/UniTTS_wo_aug/unseen.wav"></audio></td>
            </tr>

        </table>

        unseen*: synthesized with speaker ema's id + kes's emotion(curious).

        <br><br>


        <!-- <h3>Ablation study</h3>

        <table style="text-align:center">
            <tr>
                <th></th>
                <th>Reference sample</th>
                <th></th>
                <th>UniTTS learned from scratch</th>
                <th>UniTTS (w/o aug)</th>
                <th>UniTTS</th>
            </tr>
            <tr>
                <td>sample 1</td>
                <td><audio controls><source src="samples/speaker_similarity/GT_mel/1.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/speaker_similarity/separate_embedding/1.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/gradient_reversal/1.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/UniTTS_wo_aug/1.wav"></audio></td>
            </tr>
            <tr>
                <td>sample 2</td>
                <td><audio controls><source src="samples/speaker_similarity/GT_mel/2.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/speaker_similarity/separate_embedding/2.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/gradient_reversal/2.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/UniTTS_wo_aug/2.wav"></audio></td>
            </tr>

            <tr>
                <td>sample 3</td>
                <td><audio controls><source src="samples/speaker_similarity/GT_mel/3.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/speaker_similarity/separate_embedding/3.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/gradient_reversal/3.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/UniTTS_wo_aug/3.wav"></audio></td>
            </tr>

            <tr>
                <td>sample 4</td>
                <td><audio controls><source src="samples/speaker_similarity/GT_mel/4.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/speaker_similarity/separate_embedding/4.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/gradient_reversal/4.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/UniTTS_wo_aug/4.wav"></audio></td>
            </tr>
            <tr>
                <td>unseen*</td>
                <td><audio controls><source src="samples/speaker_similarity/GT_mel/unseen.wav"></audio></td>
                <td></td>
                <td><audio controls><source src="samples/speaker_similarity/separate_embedding/unseen.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/gradient_reversal/unseen.wav"></audio></td>
                <td><audio controls><source src="samples/speaker_similarity/UniTTS_wo_aug/unseen.wav"></audio></td>
            </tr>

        </table> -->

    </div>
    
  </body>
</html>
